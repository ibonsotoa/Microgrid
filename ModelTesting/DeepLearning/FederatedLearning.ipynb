{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:40.169982Z",
     "start_time": "2025-03-26T20:38:40.164549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "7388d69034bed509",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:40.467592Z",
     "start_time": "2025-03-26T20:38:40.463361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuración general\n",
    "folder_path = r\"C:\\Users\\Ibon\\PycharmProjects\\Microgrid\\TrainTestSplit\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "2e6d32967842b1de",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:40.481260Z",
     "start_time": "2025-03-26T20:38:40.475797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función para cargar y preprocesar datos (usada tanto para entrenamiento como para test)\n",
    "def load_and_preprocess(files, all_sources):\n",
    "    df_list = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, parse_dates=[\"Time Stamp (local standard time) yyyy-mm-ddThh:mm:ss\"])\n",
    "        df = df.drop(columns='Time Stamp (local standard time) yyyy-mm-ddThh:mm:ss')\n",
    "        # Muestreo estratificado\n",
    "        df_sampled = df.groupby('source', group_keys=False).apply(lambda x: x.sample(frac=0.4, random_state=42))\n",
    "        df_list.append(df_sampled)\n",
    "    full_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # One-hot encoding con categorías fijas\n",
    "    full_df['source'] = pd.Categorical(full_df['source'], categories=all_sources)\n",
    "    full_df = pd.get_dummies(full_df, columns=['source'], prefix='src', dtype=np.float32)\n",
    "    \n",
    "    return full_df\n"
   ],
   "id": "28c7cb631480881a",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:40.756999Z",
     "start_time": "2025-03-26T20:38:40.748376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función para preparar tensores a partir de DataFrame\n",
    "def prepare_data(df, scaler=None):\n",
    "    # Separar características y target\n",
    "    X = df.drop(columns=['Pmp (W)']).values.astype(np.float32)\n",
    "    y = df['Pmp (W)'].values.astype(np.float32)\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "    X_tensor = torch.tensor(X).to(device)\n",
    "    y_tensor = torch.tensor(y).unsqueeze(1).to(device)\n",
    "    return X_tensor, y_tensor, scaler"
   ],
   "id": "5e637629cc88a2b9",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:41.020890Z",
     "start_time": "2025-03-26T20:38:41.012494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definición del modelo\n",
    "class EnhancedDNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "id": "848f8b2461eecb40",
   "outputs": [],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:41.293541Z",
     "start_time": "2025-03-26T20:38:41.287696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parámetros del Federated Learning\n",
    "federated_rounds = 5         # número de rondas federadas\n",
    "local_epochs = 40             # épocas locales por cada ronda\n",
    "batch_size = 512\n",
    "lr = 0.0001\n",
    "weight_decay = 1e-4"
   ],
   "id": "41c47e1886f0db82",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:41.550466Z",
     "start_time": "2025-03-26T20:38:41.542701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir los clientes y sus archivos de entrenamiento\n",
    "clients = {\n",
    "    \"cocoa\": [f for f in os.listdir(folder_path) if f.endswith('.csv') and \"train\" in f and \"cocoa\" in f.lower()],\n",
    "    \"eugene\": [f for f in os.listdir(folder_path) if f.endswith('.csv') and \"train\" in f and \"eugene\" in f.lower()],\n",
    "    \"golden\": [f for f in os.listdir(folder_path) if f.endswith('.csv') and \"train\" in f and \"golden\" in f.lower()]\n",
    "}\n",
    "\n",
    "# Para test, se puede hacer lo mismo (o unir todos los test en uno solo)\n",
    "test_files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and \"test\" in f]\n"
   ],
   "id": "4f1e274429f0d759",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:43.033793Z",
     "start_time": "2025-03-26T20:38:41.798266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Antes de cualquier preprocesamiento, recolectar TODAS las categorías posibles de 'source'\n",
    "all_sources = set()\n",
    "\n",
    "# Recolectar de los clientes\n",
    "for client_files in clients.values():\n",
    "    for file in client_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df_temp = pd.read_csv(file_path, usecols=['source'])\n",
    "        all_sources.update(df_temp['source'].unique())\n",
    "\n",
    "# Recolectar de los archivos de test\n",
    "for test_file in test_files:\n",
    "    file_path = os.path.join(folder_path, test_file)\n",
    "    df_temp = pd.read_csv(file_path, usecols=['source'])\n",
    "    all_sources.update(df_temp['source'].unique())\n",
    "\n",
    "all_sources = sorted(all_sources)  # Ordenar para consistencia"
   ],
   "id": "967d1f9458057752",
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:44.826127Z",
     "start_time": "2025-03-26T20:38:43.474249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cargar datos iniciales (cocoa) con todas las categorías\n",
    "temp_df = load_and_preprocess(clients[\"cocoa\"], all_sources)\n",
    "X_temp, y_temp, scaler = prepare_data(temp_df)  # Ahora scaler se entrena con todas las features\n",
    "\n",
    "# Procesar test_df con las mismas categorías\n",
    "test_df = load_and_preprocess(test_files, all_sources)\n",
    "\n",
    "input_dim = X_temp.shape[1]\n",
    "\n",
    "print(\"Columnas del dataset de entrenamiento:\", temp_df.columns)\n",
    "print(\"Columnas del dataset de test:\", test_df.columns)"
   ],
   "id": "7a1f70b7ad4758ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas del dataset de entrenamiento: Index(['POA irradiance CMP22 pyranometer (W/m2)',\n",
      "       'PV module back surface temperature (degC)', 'Pmp (W)',\n",
      "       'Dry bulb temperature (degC)', 'Relative humidity (%RH)',\n",
      "       'Atmospheric pressure (mb)',\n",
      "       'Precipitation (mm) accumulated daily total',\n",
      "       'Direct normal irradiance (W/m2)',\n",
      "       'Global horizontal irradiance (W/m2)',\n",
      "       'Diffuse horizontal irradiance (W/m2)', 'src_Cocoa_CIGS39017.csv',\n",
      "       'src_Cocoa_CIGS8-001.csv', 'src_Cocoa_CdTe75638.csv',\n",
      "       'src_Cocoa_HIT05667.csv', 'src_Cocoa_aSiMicro03036.csv',\n",
      "       'src_Cocoa_aSiTandem72-46.csv', 'src_Cocoa_aSiTriple28324.csv',\n",
      "       'src_Cocoa_mSi0166.csv', 'src_Cocoa_mSi0188.csv',\n",
      "       'src_Cocoa_mSi460A8.csv', 'src_Cocoa_xSi12922.csv',\n",
      "       'src_Eugene_CIGS39017.csv', 'src_Eugene_CIGS8-001.csv',\n",
      "       'src_Eugene_CdTe75638.csv', 'src_Eugene_HIT05667.csv',\n",
      "       'src_Eugene_aSiMicro03036.csv', 'src_Eugene_aSiTandem72-46.csv',\n",
      "       'src_Eugene_aSiTriple28324.csv', 'src_Eugene_mSi0166.csv',\n",
      "       'src_Eugene_mSi0188.csv', 'src_Eugene_mSi460A8.csv',\n",
      "       'src_Eugene_xSi12922.csv', 'src_Golden_CIGS1-001.csv',\n",
      "       'src_Golden_CIGS39013.csv', 'src_Golden_CdTe75669.csv',\n",
      "       'src_Golden_HIT05662.csv', 'src_Golden_aSiMicro03038.csv',\n",
      "       'src_Golden_aSiTandem90-31.csv', 'src_Golden_aSiTriple28325.csv',\n",
      "       'src_Golden_mSi0247.csv', 'src_Golden_mSi0251.csv',\n",
      "       'src_Golden_mSi460BB.csv', 'src_Golden_xSi11246.csv'],\n",
      "      dtype='object')\n",
      "Columnas del dataset de test: Index(['POA irradiance CMP22 pyranometer (W/m2)',\n",
      "       'PV module back surface temperature (degC)', 'Pmp (W)',\n",
      "       'Dry bulb temperature (degC)', 'Relative humidity (%RH)',\n",
      "       'Atmospheric pressure (mb)',\n",
      "       'Precipitation (mm) accumulated daily total',\n",
      "       'Direct normal irradiance (W/m2)',\n",
      "       'Global horizontal irradiance (W/m2)',\n",
      "       'Diffuse horizontal irradiance (W/m2)', 'src_Cocoa_CIGS39017.csv',\n",
      "       'src_Cocoa_CIGS8-001.csv', 'src_Cocoa_CdTe75638.csv',\n",
      "       'src_Cocoa_HIT05667.csv', 'src_Cocoa_aSiMicro03036.csv',\n",
      "       'src_Cocoa_aSiTandem72-46.csv', 'src_Cocoa_aSiTriple28324.csv',\n",
      "       'src_Cocoa_mSi0166.csv', 'src_Cocoa_mSi0188.csv',\n",
      "       'src_Cocoa_mSi460A8.csv', 'src_Cocoa_xSi12922.csv',\n",
      "       'src_Eugene_CIGS39017.csv', 'src_Eugene_CIGS8-001.csv',\n",
      "       'src_Eugene_CdTe75638.csv', 'src_Eugene_HIT05667.csv',\n",
      "       'src_Eugene_aSiMicro03036.csv', 'src_Eugene_aSiTandem72-46.csv',\n",
      "       'src_Eugene_aSiTriple28324.csv', 'src_Eugene_mSi0166.csv',\n",
      "       'src_Eugene_mSi0188.csv', 'src_Eugene_mSi460A8.csv',\n",
      "       'src_Eugene_xSi12922.csv', 'src_Golden_CIGS1-001.csv',\n",
      "       'src_Golden_CIGS39013.csv', 'src_Golden_CdTe75669.csv',\n",
      "       'src_Golden_HIT05662.csv', 'src_Golden_aSiMicro03038.csv',\n",
      "       'src_Golden_aSiTandem90-31.csv', 'src_Golden_aSiTriple28325.csv',\n",
      "       'src_Golden_mSi0247.csv', 'src_Golden_mSi0251.csv',\n",
      "       'src_Golden_mSi460BB.csv', 'src_Golden_xSi11246.csv'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:45.082582Z",
     "start_time": "2025-03-26T20:38:45.072562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inicializar modelo global\n",
    "global_model = EnhancedDNN(input_dim).to(device)\n",
    "global_model.train()"
   ],
   "id": "ed0e968988cc0472",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedDNN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=42, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:45.338483Z",
     "start_time": "2025-03-26T20:38:45.330202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función de entrenamiento local\n",
    "def local_train(model, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * xb.size(0)\n",
    "        avg_loss = running_loss / len(train_loader.dataset)\n",
    "        # Se puede imprimir la pérdida local si se desea:\n",
    "        print(f\"Local epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
    "    return model.state_dict(), len(train_loader.dataset)"
   ],
   "id": "6e2ff7772e2391de",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-26T20:38:45.636952Z",
     "start_time": "2025-03-26T20:38:45.628904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir la función para promediar los pesos (FedAvg) ponderados por el tamaño del dataset\n",
    "def fed_avg(state_dicts, data_sizes):\n",
    "    avg_state = copy.deepcopy(state_dicts[0])\n",
    "    total_samples = sum(data_sizes)\n",
    "\n",
    "    for key in avg_state.keys():\n",
    "        # Verificar si el tensor es de tipo entero (LongTensor)\n",
    "        if avg_state[key].dtype in [torch.int64, torch.long]:\n",
    "            # No promediamos los tensores enteros, solo copiamos el valor del primer cliente\n",
    "            avg_state[key] = state_dicts[0][key].clone()\n",
    "        else:\n",
    "            # Inicializar con ceros en tipo float32\n",
    "            avg_state[key] = torch.zeros_like(avg_state[key], dtype=torch.float32)\n",
    "\n",
    "            # Promediar los parámetros de tipo float\n",
    "            for state, size in zip(state_dicts, data_sizes):\n",
    "                weight = size / total_samples\n",
    "                avg_state[key] += state[key].float() * weight\n",
    "\n",
    "    return avg_state\n",
    "\n"
   ],
   "id": "ef3ef47eb2a7200b",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-26T20:38:45.929378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Comenzamos la simulación de Federated Learning\n",
    "criterion = nn.MSELoss()\n",
    "# Variables para guardar el mejor modelo federado\n",
    "best_test_loss = np.inf\n",
    "best_federated_model_path = \"best_federated_model.pth\"\n",
    "\n",
    "print(\"=== Iniciando entrenamiento federado ===\")\n",
    "for round in range(1, federated_rounds+1):\n",
    "    print(f\"\\n--- Ronda Federada {round} ---\")\n",
    "    local_state_dicts = []\n",
    "    data_sizes = []\n",
    "    # Entrenamiento local para cada cliente\n",
    "    for client_name, files in clients.items():\n",
    "        print(f\"Entrenando cliente: {client_name}\")\n",
    "        client_df = load_and_preprocess(files, all_sources)\n",
    "        X_local, y_local, _ = prepare_data(client_df, scaler)\n",
    "        local_dataset = TensorDataset(X_local, y_local)\n",
    "        local_loader = DataLoader(local_dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Clonar el modelo global para entrenamiento local\n",
    "        local_model = copy.deepcopy(global_model)\n",
    "        optimizer_local = optim.Adam(local_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Entrenamiento local\n",
    "        local_state, n_samples = local_train(local_model, local_loader, criterion, optimizer_local, local_epochs)\n",
    "        local_state_dicts.append(local_state)\n",
    "        data_sizes.append(n_samples)\n",
    "    \n",
    "    # Promediar (FedAvg) los pesos de los clientes para actualizar el modelo global\n",
    "    global_state = fed_avg(local_state_dicts, data_sizes)\n",
    "    global_model.load_state_dict(global_state)\n",
    "    print(f\"Ronda {round} completada. Se han promediado los pesos de {len(clients)} clientes.\")\n",
    "    \n",
    "    # Evaluación en el conjunto de test después de cada ronda\n",
    "    X_test_tensor, y_test_tensor, _ = prepare_data(test_df, scaler)\n",
    "    global_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = global_model(X_test_tensor).cpu().numpy()\n",
    "        y_test_np = y_test_tensor.cpu().numpy()\n",
    "        test_loss = mean_squared_error(y_test_np, y_pred)\n",
    "        print(f\"Test MSE después de ronda {round}: {test_loss:.4f}\")\n",
    "    \n",
    "    # Guardar el modelo si mejora\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        torch.save(global_model.state_dict(), best_federated_model_path)\n",
    "        print(f\"Nuevo mejor modelo federado guardado: {best_federated_model_path}\")\n",
    "\n"
   ],
   "id": "d8348cbe337db272",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iniciando entrenamiento federado ===\n",
      "\n",
      "--- Ronda Federada 1 ---\n",
      "Entrenando cliente: cocoa\n",
      "Local epoch 1, Loss: 1515.4080\n",
      "Local epoch 2, Loss: 80.1815\n",
      "Local epoch 3, Loss: 56.6040\n",
      "Local epoch 4, Loss: 50.1850\n",
      "Local epoch 5, Loss: 45.7742\n",
      "Local epoch 6, Loss: 42.8415\n",
      "Local epoch 7, Loss: 39.6037\n",
      "Local epoch 8, Loss: 39.3454\n",
      "Local epoch 9, Loss: 37.6377\n",
      "Local epoch 10, Loss: 36.5518\n",
      "Local epoch 11, Loss: 34.6714\n",
      "Local epoch 12, Loss: 34.2522\n",
      "Local epoch 13, Loss: 33.6746\n",
      "Local epoch 14, Loss: 32.6134\n",
      "Local epoch 15, Loss: 31.7288\n",
      "Local epoch 16, Loss: 30.9536\n",
      "Local epoch 17, Loss: 30.2775\n",
      "Local epoch 18, Loss: 30.0192\n",
      "Local epoch 19, Loss: 30.0816\n",
      "Local epoch 20, Loss: 29.9082\n",
      "Local epoch 21, Loss: 28.5408\n",
      "Local epoch 22, Loss: 28.6165\n",
      "Local epoch 23, Loss: 28.1384\n",
      "Local epoch 24, Loss: 28.8780\n",
      "Local epoch 25, Loss: 27.4327\n",
      "Local epoch 26, Loss: 27.1898\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Evaluación final del modelo global (o el mejor modelo guardado)\n",
    "global_model.load_state_dict(torch.load(best_federated_model_path))\n",
    "global_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = global_model(X_test_tensor).cpu().numpy()\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    mse = mean_squared_error(y_test_np, y_pred)\n",
    "    mae = mean_absolute_error(y_test_np, y_pred)\n",
    "    r2 = r2_score(y_test_np, y_pred)\n",
    "    print(\"\\n=== Evaluación Final del Mejor Modelo Federado ===\")\n",
    "    print(f\"Test MSE: {mse:.4f}\")\n",
    "    print(f\"Test MAE: {mae:.4f}\")\n",
    "    print(f\"Test R2: {r2:.4f}\")\n",
    "\n",
    "# (Opcional) Graficar resultados en Test\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Predicciones vs Reales')\n",
    "plt.scatter(y_test_np, y_pred, alpha=0.3)\n",
    "plt.plot([y_test_np.min(), y_test_np.max()], [y_test_np.min(), y_test_np.max()], 'r--')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(132)\n",
    "residuals = y_test_np - y_pred\n",
    "plt.hist(residuals, bins=50, density=True, alpha=0.6)\n",
    "plt.title('Distribución de Residuos')\n",
    "plt.xlabel('Residuo')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(y_pred, label=\"Predicciones\")\n",
    "plt.plot(y_test_np, label=\"Valores Reales\", alpha=0.7)\n",
    "plt.title('Predicciones vs Reales')\n",
    "plt.xlabel('Muestras')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c0f45ae52658ad0b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
